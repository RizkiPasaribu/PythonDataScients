{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49914a21-d79b-42f9-8c18-4e6b28f971d5",
   "metadata": {},
   "source": [
    "# **1 Pada Gambar**\n",
    "    - baca image -> flatten -> csv1\n",
    "        - untuk baca path dari folder gambar bisa pakai pakege glob\n",
    "    - kalau pada gambar data di baca dulu dalam pixel, trus di flatten, trus dimasukkan ke csv\n",
    "    - kalau gambar bewarna itu ada 3 warna atau di sebut 3 chanel (RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c3dc6b-d111-4ff6-9061-8f66c9a17c5f",
   "metadata": {},
   "source": [
    "# **2 Pada Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f946d2-e291-4ab8-8c85-cb1689baafa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/rizki/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/rizki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95407b23-f46c-4497-84ac-091e99541c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from jcopml.pipeline import num_pipe, cat_pipe\n",
    "from jcopml.utils import save_model, load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8df0f0-c7a1-457f-af5b-e15283764be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librari pemecah kata, ada satu lagi berdasarkan kata yaitu sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#livrary untuk menemukan kata yang umum\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#librari untuk memisahkan tanda baca\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words(\"indonesian\") + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74c91203-da20-46f6-a740-e1720eb06e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ada', 'adalah', 'adanya', 'adapun', 'agak']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"indonesian\")[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf042c2d-101c-49d4-a67d-5a77639d565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4c5ce-b503-4580-9f1f-ed3d728809c1",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed4ef6d8-94ac-462e-83c7-0be6ded80559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teks</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[PROMO] Beli paket Flash mulai 1GB di MY TELKO...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Teks  label\n",
       "0  [PROMO] Beli paket Flash mulai 1GB di MY TELKO...      1\n",
       "1  2.5 GB/30 hari hanya Rp 35 Ribu Spesial buat A...      1\n",
       "2  2016-07-08 11:47:11.Plg Yth, sisa kuota Flash ...      1\n",
       "3  2016-08-07 11:29:47.Plg Yth, sisa kuota Flash ...      1\n",
       "4  4.5GB/30 hari hanya Rp 55 Ribu Spesial buat an...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/spam.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b1ae5c-74d1-489a-944a-520a60dec38d",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656546d0-f74c-4305-82a9-6970f5a97c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((914,), (229,), (914,), (229,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"Teks\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "#karna klasifikasi kita pakai stratify\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d8bb8-3903-4471-ad1d-1528d31e4daf",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9e0d09-db9a-4acf-8c85-029a3e8e5af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#klw pakai Countvectorizer dia sistem nya (BoW bag of Word)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from jcopml.tuning import random_search_params as rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6d9e8b-aded-4006-b547-255e2fe71415",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n",
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algo__C': 13.961497016794214, 'algo__fit_intercept': True}\n",
      "1.0 0.9781659388646288 0.96388769053782\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"prep\", TfidfVectorizer(tokenizer= word_tokenize, stop_words=sw_indo)),\n",
    "    (\"algo\", LogisticRegression(solver='lbfgs', n_jobs=-1, random_state=42))\n",
    "])\n",
    "\n",
    "#Tuning\n",
    "model = RandomizedSearchCV(pipeline, rsp.logreg_params, n_iter=50, cv=3, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "print(model.score(X_train, y_train),  model.score(X_test, y_test), model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84fbbde1-0514-49a6-8ba9-f81945b42145",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [\"Ajukan segera pinjaman online dengan mudah tanpa potongan. Proses cepat cair. Dana 5 juta/500 juta. Info WA langsung nomor +6282123123123\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff68059-cd61-461d-958e-cb48721a6072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01818085 0.98181915]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print (model.predict_proba(y_pred))\n",
    "print (model.predict(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "183eb681-b16e-4fa4-903f-7d2ca6203ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = [\"Rizki Pinjam duit mu dong aku lagi butuh ni untuk biaya obat dari wahyu\"]\n",
    "model.predict(y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abd55b-a787-4934-86a4-439dec9e4654",
   "metadata": {},
   "source": [
    "# **Predict Smilarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1660ed4c-dfb9-495d-901b-e0af48b946cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Librari pemecah kata, ada satu lagi berdasarkan kata yaitu sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#livrary untuk menemukan kata yang umum\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#librari untuk memisahkan tanda baca\n",
    "from string import punctuation\n",
    "\n",
    "sw_indo = stopwords.words(\"indonesian\") + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0e9c1a27-2192-4282-a76c-5f9758a22624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#klw pakai Countvectorizer dia sistem nya (BoW bag of Word)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Library untuk cek smilarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "784ae26c-a7e8-4b15-8f18-45771f9cb9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jakarta Dikangkangi Para Preman\\nKALAU tak pun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Penyimpangan di Setpres Seolah Terjadi Sekaran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Kekerasan, Elite agar Duduk Bersama\\nSeju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                teks\n",
       "0  Ginandjar Tetap Ditahan. Jaksa Agung Dilaporka...\n",
       "1  Jakarta Dikangkangi Para Preman\\nKALAU tak pun...\n",
       "2  Penyimpangan di Setpres Seolah Terjadi Sekaran...\n",
       "3  Dibayarkan, Rapel Kenaikan Gaji Pegawai Pos\\nK...\n",
       "4  Stop Kekerasan, Elite agar Duduk Bersama\\nSeju..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/kompas.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13038f2e-0ff6-485a-9c65-9ae41cacbbbc",
   "metadata": {},
   "source": [
    "## **Predict Smilarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "87008117-a1e5-4cf5-aced-4e36e3c43bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rizki/anaconda3/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1,2), tokenizer=word_tokenize, stop_words=sw_indo)\n",
    "tfidf_matriks = tfidf.fit_transform(df[\"teks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eb621286-d405-4c57-8411-f3da8b2b1b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2008x548426 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1173722 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matriks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f2c93815-03ec-44a2-bb30-0cb05ac97347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.00858328, 0.01060043, ..., 0.00856287, 0.00677808,\n",
       "        0.01513341]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = cosine_similarity(tfidf_matriks[0], tfidf_matriks)\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59d80c9c-2d2c-49de-8af7-7b217a383399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 932, 1131, 1593, ...,  215,  144,    0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Urutkan value dari terkecil ke terbesar tetapi yang di return index array nya bukai nilai array nya\n",
    "sim.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9ce16a7b-61a9-4363-80a4-c0dd48c0829d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kejaksaan Agung Terbitkan Surat Penahanan Baru\\nKejaksaan Agung (Kejagung) akhirnya menerbitkan surat perintah penahanan yang baru terhadap mantan Menteri Pertambangan dan Energi Ginandjar Kartasasmita'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"teks\"][144][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6fd5fd21-ef4b-42fa-9168-1d245218bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kuasa Hukum Ginandjar Bertahan di Rutan\\nSejumlah kuasa hukum Ginandjar Kartasasmita hingga hari Selasa (17/4) pukul 22.00 masih bertahan di ruang tahanan (rutan) Kejaksaan Agung (Kejagung). Selasa pag'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"teks\"][215][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6efa2fe-61ac-431e-abe9-e9fc8b7cb00f",
   "metadata": {},
   "source": [
    "# **Ekstrak Keyword**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b8b3fc15-6885-4ac4-b944-5b7211992d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zuniga memilih',\n",
       " 'zunnatul',\n",
       " 'zunnatul mafruhah',\n",
       " 'zurich',\n",
       " 'zurich northholt',\n",
       " 'zw',\n",
       " 'zw suparman',\n",
       " 'zw tim',\n",
       " 'zx',\n",
       " 'zx diserbu']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tfidf.get_feature_names()\n",
    "vocab[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0626010-c6d4-423c-99ec-3872e65cd59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([274212, 365469, 365468, ..., 386379, 436652, 169219])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ektrak = tfidf_matriks.toarray()[0].argsort()\n",
    "ektrak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30e4a6af-d441-42ce-bd16-ce5b010fac07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ginandjar'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[169219]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6077b75f-a730-45d6-ae05-d39d76061ade",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ginandjar',\n",
       " 'putusan',\n",
       " 'penahanan',\n",
       " 'hukum ginandjar',\n",
       " 'kuasa hukum',\n",
       " 'rusman',\n",
       " 'kejaksaan',\n",
       " 'hakim rusman',\n",
       " 'kuasa',\n",
       " '9 april']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[idx] for idx in reversed(ektrak[-10:])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d227228-f9bc-416e-9495-47062d233c10",
   "metadata": {},
   "source": [
    "## **Cek Highlit Berita**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "38bac4b1-57fd-462e-b44b-5dfe5e68b7b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "berita1 = \"\"\"\n",
    "Menteri Komunikasi dan Informatika Johnny G. Plate mengatakan pemerintah telah menyiapkan laman vaksinIn.dto.kemkes.go.id untuk para WNI maupun WNA untuk mendaftar dan mengajukan verifikasi.\n",
    "Proses verifikasi akan dikonfirmasi melalui email yang sudah didaftarkan di laman tersebut dalam waktu maksimal 3 hari kerja.\n",
    "\"Setelah itu pendaftar harus masuk ke dalam aplikasi PeduliLindungi untuk mengklaim sertifikat vaksin yang nanti muncul setelah diverifikasi,\" ujar Johnny, Kamis (16/9).\n",
    "Setelah itu, lanjutnya, WNI atau WNA tersebut bisa menggunakan aplikasi PeduliLindungi untuk mengakses berbagai tempat fasilitas umum.\n",
    "Berkas yang harus disiapkan bagi WNI berupa KTP dengan NIK, ID yang dipakai untuk verifikasi adalah NIK dan Kartu Vaksinasi. Verifikasi akan dilakukan oleh Kementerian Kesehatan.\n",
    "Adapun berkas yang harus disiapkan oleh WNA, lanjut Johnny, adalah izin diplomatik dari Kementerian Luar Negeri atau izin tinggal dari imigrasi dan kartu vaksinasi. ID yang dipakai untuk verifikasi adalah nomor paspor.\n",
    "Verifikasi bagi WNA dengan izin diplomatik dilakukan oleh Kementerian Luar Negeri, sedangkan verifikasi bagi WNA dengan izin tinggal masih dalam proses finalisasi antara Kemenkes dengan Kemenlu.\n",
    "Selain itu, WNI dan WNA yang mendapatkan vaksinasi di luar negeri juga dapat menggunakan aplikasi PeduliLindungi untuk memudahkan dalam memperlancar akomodasi ke fasilitas publik.\n",
    "\"Penambahan fitur ini dapat membantu pemerintah dalam melakukan tracing dengan cepat untuk mengendalikan pandemi,\" ujarnya.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "852f90c0-bbf4-4931-9363-c18f69bbd7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x548426 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 69 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matriks1 = tfidf.transform([berita1])\n",
    "tfidf_matriks1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "06666e4a-15fc-4341-becf-c3f9d49bbba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ektrak1 = tfidf_matriks1.toarray()[0].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6675be78-40ad-4d5f-884f-cc223e9f470f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wna',\n",
       " 'verifikasi',\n",
       " 'wni',\n",
       " 'johnny',\n",
       " 'aplikasi',\n",
       " 'vaksinasi',\n",
       " 'id',\n",
       " 'izin tinggal',\n",
       " 'izin',\n",
       " 'kementerian']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab[idx] for idx in reversed(ektrak1[-10:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cb8e45c6-434a-4381-8119-759cc23ffd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# atau dapat dibuat fungsi sebagai berikut\n",
    "\n",
    "def HighlitBerita (berita, tfidf, jlhKataHighlit = 10):\n",
    "    tfidf_matriks1 = tfidf.transform([berita])\n",
    "    ektrak1 = tfidf_matriks1.toarray()[0].argsort()\n",
    "    return [vocab[idx] for idx in reversed(ektrak1[-jlhKataHighlit:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "726c8319-c4db-4f49-9107-a0dbbaaa8847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wna',\n",
       " 'verifikasi',\n",
       " 'wni',\n",
       " 'johnny',\n",
       " 'aplikasi',\n",
       " 'vaksinasi',\n",
       " 'id',\n",
       " 'izin tinggal',\n",
       " 'izin',\n",
       " 'kementerian']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HighlitBerita(berita1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
